#!/usr/bin/env python3
"""
PhenoHunter CLI - Enhanced command-line interface for cannabis breeding optimization.

Professional CLI with colors, progress bars, and improved user experience.
"""

import argparse
import sys
from pathlib import Path
import os

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from src.phenohunter_scientific import create_phenohunter
from src.cli_utils import (
    Colors, print_header, print_success, print_error, print_warning,
    print_info, print_section, print_table_row, format_chemical,
    format_metric, print_banner, ProgressBar
)
from src.__version__ import __version__, VERSION_INFO
import pandas as pd
import numpy as np


def cmd_train(args):
    """Train models on a strain database."""
    print_banner()
    print_header("TRAINING MODELS")

    # Load data
    print_info(f"Loading strain database from {args.data}")
    try:
        df = pd.read_csv(args.data)
        print_success(f"Loaded {len(df)} strains with {len(df.columns)} features")
    except FileNotFoundError:
        print_error(f"File not found: {args.data}")
        return 1
    except Exception as e:
        print_error(f"Failed to load data: {e}")
        return 1

    # Initialize PhenoHunter
    print_info("Initializing PhenoHunter...")
    try:
        ph = create_phenohunter(args.config)
    except Exception as e:
        print_error(f"Failed to initialize: {e}")
        return 1

    # Load and validate
    print_info("Validating strain database...")
    warnings = ph.load_strain_database(df, validate=not args.no_validate)

    if warnings and args.show_warnings:
        print_warning("Validation warnings detected:")
        for category, warning_list in warnings.items():
            for warning in warning_list[:5]:
                print(f"  {Colors.DIM}[{category}]{Colors.RESET} {warning}")

    # Train VAE
    print_section(f"Training VAE ({args.epochs} epochs)")
    history = ph.train_vae(epochs=args.epochs, verbose=args.verbose)
    print_success(f"VAE training complete. Final loss: {history['train_loss'][-1]:.4f}")

    # Train effect predictors
    if not args.skip_effects:
        print_section("Training Effect Predictors")
        metrics = ph.train_effect_predictors(auto_generate_targets=True)
        print_success(f"Trained {len(metrics)} effect predictors")

    # Save model
    if args.save:
        print_info(f"Saving model to {args.save}")
        import torch
        torch.save(ph.vae.state_dict(), args.save)
        print_success(f"Model saved successfully")

    # Print summary
    print_section("Training Summary")
    print(ph.get_summary_report())

    return 0


def cmd_cross(args):
    """Generate a hybrid cross between two parents."""
    print_banner()
    print_header("GENERATING F1 HYBRID")

    # Load data
    print_info(f"Loading strain database from {args.data}")
    try:
        df = pd.read_csv(args.data)
        print_success(f"Loaded {len(df)} strains")
    except Exception as e:
        print_error(f"Failed to load data: {e}")
        return 1

    # Validate parents exist
    if args.parent1 not in df['strain_name'].values:
        print_error(f"Parent '{args.parent1}' not found in database")
        return 1
    if args.parent2 not in df['strain_name'].values:
        print_error(f"Parent '{args.parent2}' not found in database")
        return 1

    # Initialize and train
    print_info("Initializing PhenoHunter...")
    ph = create_phenohunter(args.config)
    ph.load_strain_database(df, validate=False)

    print_info(f"Training models ({args.epochs} epochs)...")
    with ProgressBar(args.epochs, "Training") as pbar:
        ph.train_vae(epochs=args.epochs, verbose=False)
        pbar.update(args.epochs)

    ph.train_effect_predictors(auto_generate_targets=True)
    print_success("Models trained")

    # Generate F1
    print_section("Generating F1 Hybrid")
    print_info(f"Parents: {Colors.CYAN}{args.parent1}{Colors.RESET} × {Colors.CYAN}{args.parent2}{Colors.RESET}")
    print_info(f"Contribution ratio: {args.ratio:.0%} / {1-args.ratio:.0%}")

    try:
        f1_result = ph.generate_f1_hybrid(
            parent1_name=args.parent1,
            parent2_name=args.parent2,
            parent1_weight=args.ratio,
            n_samples=args.samples
        )
    except Exception as e:
        print_error(f"Failed to generate hybrid: {e}")
        return 1

    # Print results
    print_section("F1 Hybrid Results")
    print_table_row("Stability Score", f"{f1_result.stability_score:.3f}")
    print_table_row("Heterosis Score", f"{f1_result.heterosis_score:.3f}")

    print_section("Chemical Profile")
    feature_names = ph.feature_columns
    for i, feat in enumerate(feature_names[:10]):  # Show first 10
        mean = f1_result.offspring_profile[i]
        std = f1_result.offspring_std[i]
        print(f"  {format_chemical(feat, mean, std)}")

    if len(feature_names) > 10:
        print(f"  {Colors.DIM}... and {len(feature_names) - 10} more{Colors.RESET}")

    if f1_result.predicted_effects:
        print_section("Predicted Effects")
        sorted_effects = sorted(
            f1_result.predicted_effects.items(),
            key=lambda x: x[1],
            reverse=True
        )
        for effect, prob in sorted_effects:
            bar_length = int(prob * 30)
            bar = "█" * bar_length + "░" * (30 - bar_length)
            print(f"  {Colors.CYAN}{effect:<20}{Colors.RESET}: {prob:6.1%} [{bar}]")

    # Save if requested
    if args.output:
        ph.export_results([f1_result], args.output)
        print_success(f"Results saved to {args.output}")

    # Visualize
    if args.visualize:
        print_info("Generating visualization...")
        try:
            ph.visualize_breeding_result(f1_result, show_uncertainty=True)
            print_success("Visualization complete")
        except Exception as e:
            print_warning(f"Visualization failed: {e}")

    return 0


def cmd_f2(args):
    """Generate an F2 population from parents."""
    print_banner()
    print_header("GENERATING F2 POPULATION")

    # Load data
    print_info(f"Loading strain database from {args.data}")
    try:
        df = pd.read_csv(args.data)
        print_success(f"Loaded {len(df)} strains")
    except Exception as e:
        print_error(f"Failed to load data: {e}")
        return 1

    # Initialize and train
    print_info("Initializing and training models...")
    ph = create_phenohunter(args.config)
    ph.load_strain_database(df, validate=False)
    ph.train_vae(epochs=args.epochs, verbose=False)
    ph.train_effect_predictors(auto_generate_targets=True)
    print_success("Models trained")

    # Generate F1
    print_info("Generating F1 parent...")
    f1_result = ph.generate_f1_hybrid(
        parent1_name=args.parent1,
        parent2_name=args.parent2,
        parent1_weight=args.ratio,
        n_samples=100
    )

    # Generate F2
    print_section(f"Generating F2 Population ({args.count} offspring)")
    f2_population = ph.generate_f2_population(f1_result, n_offspring=args.count)

    print_success(f"Generated {len(f2_population)} F2 offspring")
    avg_stability = np.mean([r.stability_score for r in f2_population])
    print_table_row("Average Stability", f"{avg_stability:.3f}")

    # Rank by trait
    if args.trait:
        print_section(f"Top 5 Candidates for {args.trait}")
        sorted_pop = sorted(
            f2_population,
            key=lambda x: x.predicted_effects.get(args.trait, 0),
            reverse=True
        )

        for i, result in enumerate(sorted_pop[:5], 1):
            score = result.predicted_effects.get(args.trait, 0)
            print(f"  {Colors.BOLD}{i}.{Colors.RESET} Stability: {result.stability_score:.3f}, {args.trait}: {score:.1%}")

    # Save
    if args.output:
        ph.export_results(f2_population, args.output)
        print_success(f"Results saved to {args.output}")

    return 0


def cmd_backcross(args):
    """Generate backcross offspring."""
    print_banner()
    print_header(f"GENERATING BACKCROSS (BX{args.generation})")

    # Load data
    print_info(f"Loading strain database from {args.data}")
    try:
        df = pd.read_csv(args.data)
    except Exception as e:
        print_error(f"Failed to load data: {e}")
        return 1

    # Initialize and train
    ph = create_phenohunter(args.config)
    ph.load_strain_database(df, validate=False)
    print_info("Training models...")
    ph.train_vae(epochs=args.epochs, verbose=False)
    ph.train_effect_predictors(auto_generate_targets=True)

    # Generate F1
    print_info("Generating F1...")
    f1_result = ph.generate_f1_hybrid(
        parent1_name=args.parent1,
        parent2_name=args.parent2,
        parent1_weight=0.5,
        n_samples=100
    )

    # Generate backcross
    print_info(f"Backcrossing to {args.backcross_to}...")
    bx_result = ph.backcross(
        f1_result,
        parent_name=args.backcross_to,
        backcross_generation=args.generation
    )

    # Print results
    print_section(f"BX{args.generation} Results")
    print_table_row("F1 Parents", f"{args.parent1} × {args.parent2}")
    print_table_row("Backcrossed to", args.backcross_to)
    print_table_row("Stability Score", f"{bx_result.stability_score:.3f}")
    print_table_row("Parent Contribution", f"{bx_result.parent1_weight:.1%}")

    # Save
    if args.output:
        ph.export_results([bx_result], args.output)
        print_success(f"Results saved to {args.output}")

    return 0


def cmd_analyze(args):
    """Analyze a strain or compare multiple strains."""
    print_banner()
    print_header("STRAIN ANALYSIS")

    # Load data
    try:
        df = pd.read_csv(args.data)
    except Exception as e:
        print_error(f"Failed to load data: {e}")
        return 1

    ph = create_phenohunter(args.config)
    ph.load_strain_database(df, validate=False)

    for strain_name in args.strains:
        if strain_name not in df['strain_name'].values:
            print_warning(f"Strain '{strain_name}' not found in database")
            continue

        strain_data = df[df['strain_name'] == strain_name].iloc[0]

        print_section(f"Strain: {strain_name}")
        print_table_row("Type", strain_data.get('type', 'Unknown'))

        print(f"\n  {Colors.BOLD}Chemical Profile:{Colors.RESET}")
        for feat in ph.feature_columns:
            if feat in strain_data and strain_data[feat] > 0:
                print(f"    {format_chemical(feat, strain_data[feat], unit='%')}")

    return 0


def cmd_version(args):
    """Print version information."""
    print_banner()
    print(f"{Colors.BOLD}PhenoHunter{Colors.RESET} version {Colors.GREEN}{__version__}{Colors.RESET}")
    print()
    for key, value in VERSION_INFO.items():
        if key != 'version':
            print_table_row(key.title(), value)
    return 0


def main():
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(
        description='PhenoHunter - Cannabis Breeding Optimization CLI',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
{Colors.BOLD}Examples:{Colors.RESET}
  {Colors.DIM}# Train models{Colors.RESET}
  phenohunt train --data strains.csv --epochs 369

  {Colors.DIM}# Generate F1 hybrid{Colors.RESET}
  phenohunt cross --data strains.csv --parent1 "Blue Dream" --parent2 "OG Kush"

  {Colors.DIM}# Generate F2 population{Colors.RESET}
  phenohunt f2 --data strains.csv --parent1 "Blue Dream" --parent2 "OG Kush" --count 10

{Colors.BOLD}Documentation:{Colors.RESET}
  https://github.com/Hosuay/C.C.R.O.P-PhenoHunt

{Colors.DIM}Version {__version__}{Colors.RESET}
        """
    )

    parser.add_argument('--version', action='store_true', help='Show version information')
    parser.add_argument('--config', type=str, help='Path to config file')
    parser.add_argument('--no-color', action='store_true', help='Disable colored output')

    subparsers = parser.add_subparsers(dest='command', help='Command to execute')

    # Train command
    train_parser = subparsers.add_parser('train', help='Train models on strain database')
    train_parser.add_argument('--data', required=True, help='Path to strain CSV file')
    train_parser.add_argument('--epochs', type=int, default=369, help='Training epochs (default: 369)')
    train_parser.add_argument('--no-validate', action='store_true', help='Skip data validation')
    train_parser.add_argument('--skip-effects', action='store_true', help='Skip effect predictor training')
    train_parser.add_argument('--save', type=str, help='Save trained model to file')
    train_parser.add_argument('--show-warnings', action='store_true', help='Show validation warnings')
    train_parser.add_argument('--verbose', action='store_true', help='Verbose training output')

    # Cross command
    cross_parser = subparsers.add_parser('cross', help='Generate F1 hybrid cross')
    cross_parser.add_argument('--data', required=True, help='Path to strain CSV file')
    cross_parser.add_argument('--parent1', required=True, help='First parent strain name')
    cross_parser.add_argument('--parent2', required=True, help='Second parent strain name')
    cross_parser.add_argument('--ratio', type=float, default=0.6, help='Parent1 contribution ratio (default: 0.6)')
    cross_parser.add_argument('--samples', type=int, default=100, help='Monte Carlo samples (default: 100)')
    cross_parser.add_argument('--epochs', type=int, default=200, help='Training epochs (default: 200)')
    cross_parser.add_argument('--output', type=str, help='Output CSV file')
    cross_parser.add_argument('--visualize', action='store_true', help='Generate visualizations')

    # F2 command
    f2_parser = subparsers.add_parser('f2', help='Generate F2 population')
    f2_parser.add_argument('--data', required=True, help='Path to strain CSV file')
    f2_parser.add_argument('--parent1', required=True, help='First parent strain name')
    f2_parser.add_argument('--parent2', required=True, help='Second parent strain name')
    f2_parser.add_argument('--ratio', type=float, default=0.5, help='Parent1 contribution ratio (default: 0.5)')
    f2_parser.add_argument('--count', type=int, default=10, help='Number of F2 offspring (default: 10)')
    f2_parser.add_argument('--trait', type=str, help='Trait to optimize for ranking')
    f2_parser.add_argument('--epochs', type=int, default=200, help='Training epochs (default: 200)')
    f2_parser.add_argument('--output', type=str, help='Output CSV file')

    # Backcross command
    bx_parser = subparsers.add_parser('backcross', help='Generate backcross offspring')
    bx_parser.add_argument('--data', required=True, help='Path to strain CSV file')
    bx_parser.add_argument('--parent1', required=True, help='First parent strain name')
    bx_parser.add_argument('--parent2', required=True, help='Second parent strain name')
    bx_parser.add_argument('--backcross-to', required=True, help='Parent to backcross to')
    bx_parser.add_argument('--generation', type=int, default=1, help='Backcross generation number (default: 1)')
    bx_parser.add_argument('--epochs', type=int, default=200, help='Training epochs (default: 200)')
    bx_parser.add_argument('--output', type=str, help='Output CSV file')

    # Analyze command
    analyze_parser = subparsers.add_parser('analyze', help='Analyze strains')
    analyze_parser.add_argument('--data', required=True, help='Path to strain CSV file')
    analyze_parser.add_argument('--strains', nargs='+', required=True, help='Strain names to analyze')

    args = parser.parse_args()

    # Handle no-color flag
    if hasattr(args, 'no_color') and args.no_color:
        Colors.disable()

    # Handle version
    if hasattr(args, 'version') and args.version:
        return cmd_version(args)

    if not args.command:
        parser.print_help()
        return 0

    # Route to appropriate command
    commands = {
        'train': cmd_train,
        'cross': cmd_cross,
        'f2': cmd_f2,
        'backcross': cmd_backcross,
        'analyze': cmd_analyze
    }

    if args.command in commands:
        try:
            return commands[args.command](args)
        except KeyboardInterrupt:
            print_warning("\nOperation cancelled by user")
            return 130
        except Exception as e:
            print_error(f"Unexpected error: {e}")
            import traceback
            if os.getenv('DEBUG'):
                traceback.print_exc()
            return 1
    else:
        parser.print_help()
        return 1


if __name__ == '__main__':
    sys.exit(main())
